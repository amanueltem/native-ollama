# Native Ollama (Spring Boot 4 + LangChain4j)

A **Spring Boot 4â€“compatible, native-friendly Retrieval-Augmented Generation (RAG) project** using **LangChain4j** and **Ollama**, without Spring AI.

This repository demonstrates how to build a **local LLM-powered CV chatbot** that:

* Runs fully **offline** (after models are pulled)
* Uses **Ollama** for chat and embeddings
* Implements **manual RAG** (document loading, chunking, embeddings, retrieval)
* Is future-ready for **GraalVM native images**

> âš ï¸ This project intentionally avoids Spring AI because Spring Boot 4 currently breaks Spring AI compatibility.

---

## âœ¨ What is implemented so far

âœ… Spring Boot 4 application (no Spring AI)

âœ… Ollama integration via **LangChain4j**

âœ… Local embedding model (`nomic-embed-text`)

âœ… Local chat model (e.g. `phi`)

âœ… Manual document loading from classpath

âœ… Manual text chunking with overlap

âœ… In-memory vector store

âœ… Similarity search over embeddings

âœ… Context-grounded prompt (strict CV-based answers)

âœ… REST API for chat and RAG-based Q&A

---

## ğŸ§  Architecture overview

```
cv.txt
  â†“ (chunking + overlap)
TextSegment
  â†“
EmbeddingModel (Ollama)
  â†“
EmbeddingStore (InMemory)
  â†“
Similarity Search
  â†“
Context Injection
  â†“
ChatModel (Ollama)
```

This is a **true RAG pipeline**, not prompt stuffing.

---

## ğŸ“‚ Project structure

```
src/main/java
â”œâ”€â”€ com.aman.native_ollama
â”‚   â”œâ”€â”€ chat
â”‚   â”‚   â”œâ”€â”€ ChatController.java
â”‚   â”‚   â””â”€â”€ conf
â”‚   â”‚       â””â”€â”€ BeansConf.java
â”‚   â””â”€â”€ document
â”‚       â””â”€â”€ DocumentLoader.java

src/main/resources
â””â”€â”€ Documents
    â””â”€â”€ cv.txt
```

---

## âš™ï¸ Requirements

* **Java 17+** (Java 21 recommended)
* **Spring Boot 4.x**
* **Ollama** installed locally
* At least **8 GB RAM** recommended for local models

---

## ğŸ¦™ Ollama setup

Install Ollama:

```
https://ollama.com
```

Pull required models:

```bash
ollama pull phi
ollama pull nomic-embed-text
```

Ensure Ollama is running:

```bash
ollama serve
```

Default endpoint used:

```
http://localhost:11434
```

---

## ğŸ”§ Configuration

All beans are configured manually to stay Spring Boot 4â€“safe.

### Chat model

```java
@Bean
public ChatModel chatModel() {
    return OllamaChatModel.builder()
            .baseUrl("http://localhost:11434")
            .modelName("phi")
            .temperature(0.7)
            .timeout(Duration.ofSeconds(60))
            .build();
}
```

### Embedding model

```java
@Bean
public EmbeddingModel embeddingModel() {
    return OllamaEmbeddingModel.builder()
            .baseUrl("http://localhost:11434")
            .modelName("nomic-embed-text")
            .timeout(Duration.ofSeconds(60))
            .build();
}
```

### Embedding store

```java
@Bean
public EmbeddingStore<TextSegment> embeddingStore() {
    return new InMemoryEmbeddingStore<>();
}
```

---

## ğŸ“„ Document loading

The CV is loaded at startup from:

```
src/main/resources/Documents/cv.txt
```

Key features:

* Manual chunking
* Chunk overlap
* TextSegment-based embeddings

This ensures **high-quality semantic retrieval** for CV-style documents.

---

## ğŸŒ REST API

### Ask a CV-grounded question (RAG)

```
POST /chat/embed
Content-Type: text/plain
```

Example request:

```text
What programming languages does Amanuel know?
```

Example response:

```text
Java, Spring Boot, and related Java ecosystem technologies.
```

If information is missing:

```text
Not mentioned in the CV.
```

---

## ğŸš€ Why this project exists

* Spring AI is **not yet stable with Spring Boot 4**
* LangChain4j provides **clean, explicit control**
* Ollama enables **local, private AI**
* Manual RAG gives **full transparency and extensibility**

This repository is meant to evolve into:

* Persistent vector stores (PostgreSQL / Qdrant)
* Conversation memory
* Native-image builds (GraalVM)
* Multi-document ingestion
* UI-based chat interfaces

---

## ğŸ›£ï¸ Planned roadmap

* [ ] Persistent embedding store
* [ ] Re-indexing endpoint
* [ ] Conversation memory
* [ ] GraalVM native image support
* [ ] Document loaders (PDF, DOCX)
* [ ] Authentication & role-based access
* [ ] Web UI (Angular / React)

---

## ğŸ” Notes on production usage

* `InMemoryEmbeddingStore` is **not production-ready**
* Load documents lazily or via admin endpoints
* Apply similarity score thresholds
* Use structured chunking for large documents

---

## ğŸ‘¤ Author

**Amanuel Temesgen**
Java & Spring Boot Engineer
Focused on native Java, AI integration, and enterprise systems

---

## ğŸ“œ License

This project is open for learning and experimentation.
License to be added.
